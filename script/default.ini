;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;               ini文件格式填写基本规则
;-------------------------------------------------------------------------------------------------------
; 1. 分号;表示注释，请勿删除注释部分
; 2. 配置项大小写敏感
; 3. []内表示section名称，用于解析，禁止修改
; 4. 不能使用缩进
; 5. 所有配置项只需要在等号 = 后配置其value值，禁止修改key名称
; 6. 部分参数可以不配置，为空时使用默认值，具体可以查看各配置项注释说明
; 7. kafka.KAFKA_HOSTNAMES和platform_list配置项属于特殊操作，具体可以查看各配置项注释说明
; 8. default.ini仅限于开发环境使用，部署时需要使用manual参数，即：sh depploy.sh manual
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

; 公共参数：所有组件都需要用到
[common_params]
; CMS数据库地址
cms.url_1 = 192.168.95.55
; CMS数据库账户
cms.user_1 = nn_cms
; CMS数据库密码
cms.passwd_1 = nn_cms1234
; CMS数据库名称
cms.dbname_1 = nn_cms
; sp_id
cms.nl_sp_id_1 = deploy_test_v218_sp
; CMS platform_id
cms.nl_platform_id_1 = deploy_test_v218

; AAA数据库地址
aaa.url_1 = 192.168.95.65
; AAA数据库账户
aaa.user_1 = root
; AAA数据库密码
aaa.passwd_1 = starcor
; AAA数据库名称
aaa.dbname_1 = nn_aaa

; ！！！
; Redis地址
redis.url = 192.168.90.77
; Redis端口，未设置时使用默认值：16379
redis.port = 16379
; Redis密码，没有密码可以放空
redis.passwd = ideal

; hive库名(平台id)
hive.platform_id = starcor

; ！！！
; @TODO 校验ftp是否可用
; FTP主机地址
ftp.host = 192.168.90.77
; FTP主机账户，未设置时使用默认值：sdk
ftp.user = sdk
; FTP主机密码，未设置时使用默认值：sdk
ftp.passwd = sdk
; FTP主机数据存放目录，为相对路径，不是FTP服务器的绝对路径，未设置时使用默认值：/
ftp.directory = /

; kafka队列地址和端口，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:9092,192.168.90.96:9092
kafka.KAFKA_HOST = 192.168.90.74:9092,192.168.90.95:9092,192.168.90.77:9092
; kafka主机映射配置，在cdh查询，需要解析后存入/etc/hosts，配置时采用二元数组格式，配置样式为：ip地址:主机名称，多个主机请用英文逗号开发，示例：192.168.90.74:slave01,192.168.90.95:master01,192.168.90.77:master02
kafka.KAFKA_HOSTNAMES = 192.168.90.74:slave01,192.168.90.95:master01,192.168.90.77:master02

; es地址，示例：slave01,slave02,slave03,slave04
es.host = slave01
; es http端口，未设置时使用默认值：9200
es.http.port = 9200
; es tcp端口，未设置时使用默认值：9300
es.tcp.port = 9300
; es集群名
es.cluster.name = bigdata

; zookeeper地址和端口，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:2181,192.168.90.96:2181,192.168.90.97:2181
zookeeper.kafka_zookeeper = 192.168.90.74:2181,192.168.90.96:2181,192.168.90.97:2181
; kafka broker地址，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:9092,192.168.90.96:9092,192.168.90.97:9092
kafka.kafka_broker = 192.168.90.74:9092,192.168.90.96:9092,192.168.90.97:9092

; yarn的ResourceManager地址（实时引擎用到），多主机用逗号分隔，示例：master02,master01
yarn.ResourceManager = master02,master01

; kylin连接URL的主机和端口，例如：192.168.90.74:7070
bdp.kylin.url = 192.168.90.74:7070
; kylin连接账户
bdp.kylin.user = ADMIN
; kylin连接密码
bdp.kylin.password = KYLIN
; neo4j 连接URL
bdp.neo4j.url = master02:7687

; 可视化平台组件参数
[reporter_system]
; 大数据请求webservice地址，需要根据IP地址和版本号自动拼接成完整URL
NL_WEBSERVICE = 192.168.90.95
; 大数据搜索请求webservice地址，需要根据IP地址和版本号自动拼接成完整URL
NL_WEBSERVICE_SEARCH = master02:8090
; 个性化推荐老接口，需要根据IP地址和版本号自动拼接成完整URL
NL_RECOMMEND_SERVICE = http://202.107.188.11:8082/?action=get_recommend_content
; 个性化推荐新接口，需要根据IP地址和版本号自动拼接成完整URL
NL_NEW_RECOMMEND_SERVICE_ALI = 192.168.90.44
; 大数据详单导出地址，需要根据IP地址和版本号自动拼接成完整URL
NL_DOWNLOAD_WEBSERVICE = 192.168.90.96
; 超级管理员账户，未设置时使用默认值：admin
SYS_LOGINID = admin
; 超级管理员密码，未设置时使用默认值：admin
SYS_LOGINPWD = admin

; 报表管理使用MySQL数据库地址
mysql.NL_DB_HOST = 192.168.90.84
; 报表管理使用MySQL数据库账户
mysql.NL_DB_USER = root
; 报表管理使用MySQL数据库密码
mysql.NL_DB_PASS = starcor
; 报表管理使用MySQL数据库名称
mysql.NL_DB_NAME = nn_big_data2.24
; 博瑞得：智能推荐接口服务地址:端口
brd.NN_BRD_URL = 192.168.90.44:8090

; 地图名称
map.MAP_NAME = starcor
; 地区启用区域编码，编码值参考 nns_address_code表
map.MAP_CODE = 000001
; 是否需要通过ip和经纬度适配地区码，默认关闭，目前只有新疆CBC需要开启（即true）
map.ip_2_latitude = false
# 地区码是否转换参数，贵州和内蒙古广电配置1，新疆配置2，其他地区若不需要转换则配置0
region.area_code_change_rule = 0
# 是否在错误码和页面ID前拼接sp_id，内蒙古需要配置为true，其他地区根据需求配置
error.is_splice_sp_id = false

; 接口服务组件参数
[sdk_ws]
; 图数据url，配置格式：主机:端口
graphxUrl = master02:7687
; presto连接地址，可以只配置主机:端口，会自动拼接成格式：jdbc:presto://master01:16060/hive/default，若是有不一致，也可以配置全称
presto.url =jdbc:presto://master01:16060/hive/starcor
; presto连接账户
presto.user = hive
; presto连接密码
presto.pwd = brd123
; 默认kylin使用视图库名称，一般保持default，如果需要变更，需要开发重新发版本变更，不支持配置该值
default.platform_id = default

; 导出服务组件参数
[ws_outfile]
; 此部分mysql参数可以与报表平台保持一致
; MySQL数据库地址，可以只配置主机:端口/数据库名称，会自动拼接成格式：jdbc:mysql://192.168.95.65:3306/nn_big_data2.16，若是有不一致，也可以配置全称
mysql.jdbcUrl = jdbc:mysql://192.168.95.65:3306/deploy_test_v218
; MySQL数据库账户
mysql.username = root
; MySQL数据库密码
mysql.password = starcor

; 数据模型服务组件参数
[data_model_service]
; MySQL配置，此MySQL为蓝鲸平台管理使用的，集群mysql一般在master02上，可以在cdh上“BLUEWHALE”->“服务范围”配置中查看蓝鲸系统管理数据库mysql相关信息
mysql.bluewhale_host = 192.168.90.77
; MySQL数据库账户
mysql.bluewhale_username = root
; MySQL数据库密码
mysql.bluewhale_password = starcor
; MySQL数据库名称
mysql.bluewhale_databasename = starcor

; MySQL配置，此MySQL为集群数据存储使用，可以在蓝鲸平台上“运维管理”->“安装配置”->“主机列表管理”->“mysql”配置中查看mysql相关信息
mysql.cluster_host = master02
; MySQL数据库账户
mysql.cluster_username = root
; MySQL数据库密码
mysql.cluster_password = starcor
; MySQL数据库名称
mysql.cluster_databasename = starcor
