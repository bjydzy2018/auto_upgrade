;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;               ini文件格式填写基本规则
;-------------------------------------------------------------------------------------------------------
; 1. 分号;表示注释，请勿删除注释部分
; 2. 配置项大小写敏感
; 3. []内表示section名称，用于解析，禁止修改
; 4. 不能使用缩进
; 5. 所有配置项只需要在等号 = 后配置其value值，禁止修改key名称
; 6. 部分参数可以不配置，为空时使用默认值，具体可以查看各配置项注释说明
; 7. kafka.KAFKA_HOSTNAMES和platform_list配置项属于特殊操作，具体可以查看各配置项注释说明
; 8. 若有不明确，可以参考同级目录的default.ini配置文件
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

; 公共参数：所有组件都需要用到
[common_params]
; CMS数据库地址
cms.url_1 =
; CMS数据库账户
cms.user_1 =
; CMS数据库密码
cms.passwd_1 =
; CMS数据库名称
cms.dbname_1 =
; CMS sp_id
cms.nl_sp_id_1 = 
; CMS platform_id
cms.nl_platform_id_1 = 

; AAA数据库地址
aaa.url_1 =
; AAA数据库账户
aaa.user_1 =
; AAA数据库密码
aaa.passwd_1 =
; AAA数据库名称
aaa.dbname_1 =

; Redis地址
redis.url = starcor-ali-hze-bigdata-master02
; Redis端口，未设置时使用默认值：16379
redis.port = 16379
; Redis密码，没有密码可以放空
redis.passwd =

; Hive数据库名称（平台ID）
hive.platform_id = cqyx

; FTP主机地址
ftp.host =
; FTP主机账户，未设置时使用默认值：sdk
ftp.user =
; FTP主机密码，未设置时使用默认值：sdk
ftp.passwd =
; FTP主机数据存放目录，未设置时使用默认值：/
ftp.directory =

; kafka队列地址和端口，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:9092,192.168.90.96:9092
kafka.KAFKA_HOST = 192.168.1.105:9092,192.168.1.106:9092,192.168.2.148:9092
; kafka主机映射配置，在cdh查询，需要解析后存入/etc/hosts，配置时采用二元数组格式，配置样式为：ip地址:主机名称，多个主机请用英文逗号开发，示例：192.168.90.74:slave01,192.168.90.95:master01,192.168.90.77:master01
kafka.KAFKA_HOSTNAMES = 192.168.1.105:starcor-ali-hze-bigdata-master01,192.168.1.106:starcor-ali-hze-bigdata-master02,192.168.2.148:starcor-ali-hze-bigdata-slave01

; es地址，示例：slave01,slave02,slave03,slave04
es.host = starcor-ali-hze-bigdata-master01,starcor-ali-hze-bigdata-master02
; es http端口，未设置时使用默认值：9200
es.http.port = 9200
; es tcp端口，未设置时使用默认值：9300
es.tcp.port = 9300
; es集群名
es.cluster.name = broadtech-bigdata

; zookeeper地址和端口，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:2181,192.168.90.96:2181,192.168.90.97:2181
zookeeper.kafka_zookeeper = starcor-ali-hze-bigdata-master02:2181,starcor-ali-hze-bigdata-slave01:2181,starcor-ali-hze-bigdata-master01:2181
; kafka broker地址，配置样式为IP:PORT，多主机用逗号分隔，示例：192.168.90.74:9092,192.168.90.96:9092,192.168.90.97:9092
kafka.kafka_broker = 192.168.1.105:9092,192.168.1.106:9092,192.168.2.148:9092

; yarn的ResourceManager地址，多主机用逗号分隔，示例：master02,master01
yarn.ResourceManager = starcor-ali-hze-bigdata-slave01,starcor-ali-hze-bigdata-slave02

; kylin连接URL
bdp.kylin.url = jdbc:kylin://starcor-ali-hze-bigdata-slave01:7070/default
; kylin连接账户
bdp.kylin.user = ADMIN
; kylin连接密码
bdp.kylin.password = KYLIN
; neo4j 连接URL
bdp.neo4j.url = starcor-ali-hze-bigdata-master02:7687

; 可视化平台组件参数
[reporter_system]
; 大数据请求webservice地址，需要根据IP地址和版本号自动拼接成完整URL
NL_WEBSERVICE = 192.168.2.148:8082
; 大数据搜索请求webservice地址，需要根据IP地址和版本号自动拼接成完整URL
NL_WEBSERVICE_SEARCH = 192.168.1.105:8082
; 个性化推荐老接口，需要根据IP地址和版本号自动拼接成完整URL
NL_RECOMMEND_SERVICE = 192.168.1.105:8082
; 个性化推荐新接口，需要根据IP地址和版本号自动拼接成完整URL
NL_NEW_RECOMMEND_SERVICE_ALI = 192.168.2.148:8090
; 大数据详单导出地址，需要根据IP地址和版本号自动拼接成完整URL
NL_DOWNLOAD_WEBSERVICE = job-bigdata.starcor.com:8181
; 超级管理员账户，未设置时使用默认值：admin
SYS_LOGINID = admin
; 超级管理员密码，未设置时使用默认值：admin
SYS_LOGINPWD = Starcor@bigdata

; 报表管理使用MySQL数据库地址
mysql.NL_DB_HOST = 192.168.1.108
; 报表管理使用MySQL数据库端口
mysql.NL_DB_USER = root
; 报表管理使用MySQL数据库密码
mysql.NL_DB_PASS = starcor
; 报表管理使用MySQL数据库名称
mysql.NL_DB_NAME = nn_big_data
; 博瑞得：智能推荐接口服务地址:端口
brd.NN_BRD_URL = http://vbas-bigdata.starcor.com:28090

; 地图名称
map.MAP_NAME = neimenggu
; 地区启用区域编码，编码值参考 nns_address_code表
map.MAP_CODE = 156451
; 是否需要通过ip和经纬度适配地区码，默认关闭，目前只有新疆CBC需要开启（即true）
map.ip_2_latitude = false

; 定时器
[crontab_list]
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &
30 1 * * *  /usr/local/php/bin/php -f /data/starcor/www/bigdata/sync_plantform/crontab/upload_aaa_csv_to_hadoop.php > /data/starcor/www/bigdata/data/log/upload_aaa_csv_to_hadoop.txt &

; 接口服务组件参数
[sdk_ws]
; 图数据url，配置格式：主机:端口
graphxUrl =
; presto连接地址，可以只配置主机:端口，会自动拼接成格式：jdbc:presto://master01:16060/hive/default，若是有不一致，也可以配置全称
presto.url = jdbc:presto://starcor-ali-hze-bigdata-master01:16060/hive/starcor
; presto连接账户
presto.user = hive
; presto连接密码
presto.pwd = 
; 默认kylin使用视图库名称，一般保持default，如果需要变更，需要开发重新发版本变更，不支持配置该值
default.platform_id = default

; 导出服务组件参数
[ws_outfile]
; 此部分mysql参数可以与报表平台保持一致
; MySQL数据库地址，可以只配置主机:端口/数据库名称，会自动拼接成格式：jdbc:mysql://192.168.95.65:3306/nn_big_data2.16，若是有不一致，也可以配置全称
mysql.jdbcUrl = jdbc:mysql://starcor-ali-hze-bigdata-slave02:3306/nn_big_data
; MySQL数据库账户
mysql.username = root
; MySQL数据库密码
mysql.password = starcor

; 数据模型服务组件参数
[data_model_service]
; MySQL配置，此MySQL为蓝鲸平台使用的，集群mysql一般在master02上，可以在cdh上“BLUEWHALE”->“服务范围”配置中查看蓝鲸系统管理数据库mysql相关信息
mysql.bluewhale_host = starcor-ali-hze-bigdata-slave01
; MySQL数据库账户
mysql.bluewhale_username = root
; MySQL数据库密码
mysql.bluewhale_password = starcor
; MySQL数据库名称
mysql.bluewhale_databasename = bdp_web

; MySQL配置，此MySQL为集群数据存储使用，可以在蓝鲸平台上“运维管理”->“安装配置”->“主机列表管理”->“mysql”配置中查看mysql相关信息
mysql.cluster_host = starcor-ali-hze-bigdata-slave02
; MySQL数据库账户
mysql.cluster_username = root
; MySQL数据库密码
mysql.cluster_password = starcor
; MySQL数据库名称，支持配置多个，使用英文逗号分开，例如：cqyx,gxgd,jscn,jxgd
mysql.cluster_databasename = starcor